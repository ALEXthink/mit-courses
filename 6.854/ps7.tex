\documentclass[psamsfonts]{amsart}

%-------Packages---------
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage[margin=1in]{geometry}
\usepackage{amsthm}
\usepackage{theorem}
\usepackage{verbatim}
\usepackage{framed}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}

\newenvironment{sol}{\vspace{0.25cm}{\large \bfseries Solution:}}{\qedsymbol}
\newenvironment{prob}[1]{\begin{framed}{\large \bfseries Problem #1:}}{\end{framed}}
\newcommand{\makenewtitle}{
    \begin{center}
    {\huge \bfseries 6.854 Advanced Algorithms} \\
    Problem Set 7\\
    \vspace{0.25cm}
    {\bfseries John Wang} \\
    Collaborators: 
    \end{center}
    \vspace{0.5cm}
}


\bibliographystyle{plain}

\voffset = -10pt
\headheight = 0pt
\topmargin = -20pt
\textheight = 690pt

\begin{document}

\makenewtitle

\begin{prob}{1}
Another way to formulate the maximum-flow problem as a linear program is via flow decomposition. Suppose we consider all $s-t$ paths $P$ in the network $G$ and let $f_P$ be the amount of flow on path $P$. Then maximum flow says to find $z = \max \sum f_P$ subject to $\sum_{P \ni e} f_P \leq u_e$ for all edges $e$ and $f_P \geq 0$ for all paths $P$. Take the dual of this LP and give an English explanation of the objective and constraints.
\end{prob}

\begin{sol}
To take the dual of this problem, we must find corresponding variables for each of the constraints. Let $y_{e}$ be the variables in the dual corresponding to the constraints $\sum_{P \ni e} f_P \leq u_e$ (one for each edge $e$). By formulating the dual's matrix, we see that the objective function for the dual becomes $min \sum_{e} u_e y_e$. 

Using the coefficients on the objective from the primal, we can find some of the constraints for the dual. Namely, we know that $y_e \geq 0$. Moreover, we find the condition $\sum_{e \in P} y_e \geq 1$ for all paths $P$ because of the objective function in the primal. Therefore, we have the following linear program:

\begin{eqnarray}
\min \sum_e u_e y_e \\
\text{s.t.} \hspace{1cm} \sum_{e \in P} y_e \geq 1 \\
y_e \geq 0
\end{eqnarray}

We can think of $y_e$ as the length of each edge. Thus, the two constraints say that the total distance from $s$ to $t$ using the edges must be positive. The second constraint, $y_e \geq 0$ says that edge lengths must be greater than 0. If we use this interpretation to interpret the objective, we find that we are attempting to minimize the sum of the length times the capacity of each edge $e$. 

In other words, we're attempting to assign lengths $y_e$ which minimize the total cost of crossing over to $t$. Since we know that $z = \max \sum f_P = \min \sum_{e} u_e y_e$, we know that minimizing the lengths will be equal to the value of the min-cut, by LP duality. If we assign lengths of 1 over all edges that cross the minimum $S$, $T$ cut, then we can be assured that $\sum f_P = \sum_{e} u_e y_e$ if we set all other edge lengths to 0. Thus, the dual of this problem is to find the minimum $S$,$T$ cut and assign edges lengths of 1 to all edges crossing the cut. 
\end{sol}

\newpage
\makenewtitle

\begin{prob}{2-a}
Explain why this captures the minimum mean cycle problem.
\end{prob}
\begin{sol}
First, we know that $f_{ij}$ represents a circulation. We see that $f_{ij}$ is constrained to be non-negative by the fact that $f_{ij} \geq 0$. Moreover, we know that the flow across the entire graph must be equal to 1 because $\sum_{i,j} f_{ij} = 1$. 

Now, we want to minimize $\sum c_{ij} f_{ij}$, which means that for each edge $(i,j)$, we want to minimize $c_{ij} f_{ij}$. Suppose for the sake of contradiction that when we decompose $\{ f_{ij} \}$ into cycles that there is some cycle $cp$ which is not a minimum mean cycle. Let us say it is of length $l$ and of cost $c$. Suppose the minimum mean cycle is of length $l^*$ and cost $c^*$. Then we know that $c/l > c^*/l^*$. We also know that the cycle $cp$ contribute $c f / l$ to the objective function, where $f$ is the circulation flowing through the cycle $cp$. 

However, if we replace the cycle $cp$ with the minimum mean cycle, then we can contributed $c^* f / l^*$ to the objective function. Notice that $c^* f / l^* < c f/l $, which means that our previous objective function was not minimal. This is a contradiction, so the circulation must go over minimum mean cycles.  
\end{sol}

\begin{prob}{2-b}
Give the dual of this linear program--it will involve maximizing a variable $\lambda$.
\end{prob}
\begin{sol}
Let us create a variable $\lambda$ which corresponds to the constraint $\sum_{i,j} f_{ij} = 1$. Since we have equality here, we know that $\lambda$ will be unbounded in sign. Let us create a set of variables $y_{i}$ which will correspond to the constraints $\sum_{j} f_{ij} - f_{ji} = 0$, one for each vertex $i$. 

Based on the primal's objective function, we see that the new constraints in the dual will be given by $\lambda + y_i - y_j \leq c_{ij}$. Moreover, by the constraint matrix for the dual, we know that we want to maximize $\lambda$. Thus, we obtain the following problem:

\begin{eqnarray}
\max \lambda \\
\text{s.t.} \hspace{1cm} \lambda + y_i - y_j \leq c_{ij}
\end{eqnarray}

Where $\lambda$ and each of the $y_i$ are unbounded in sign, and each of the constraints are set for all $i,j$. 
\end{sol}

\begin{prob}{2-c}
Give an explanation (in terms of min-cost-flow reduced costs) for why this dual formulation also captures minimum mean cycles. (Hint: how much is added to the cost of a $k$-edge cycle).
\end{prob}

\begin{sol}
If we rewrite the constraint $\lambda + y_i - y_j \leq c_{ij}$, we find that $\lambda \leq y_j + c_{ij} - y_i$. We know that $c_{ij}$ are costs, and therefore, we can think of $\lambda$ as the reduced cost, since we can think of $y_i$ as a price function defined at each vertex $i$.

This means that we can define a valid price function $y_i$ where all reduced costs are positive (if the solution to the dual is optimal). Moreover, we know that if $\lambda$ is optimal, then we must have $0 = c_{ij} - \lambda + y_j - y_i$ for some cycle, since otherwise we could make $\lambda$ marginally larger and obtain a better objective function while still satisfying the constraints.    

This means that for some cycle $K$, we have $\sum_{(i,j) \in K} c_{ij} - \lambda + y_i - y_j = 0$, which simplifies to $\sum_{(i,j) \in K} c_{ij} - \lambda = 0$ by telescoping. Therefore, we see that:
\begin{eqnarray}
\sum_{(i,j) \in C} c_{ij} = l \lambda
\end{eqnarray}

Where $l$ is the length of the cycle. Now, let us set $c$ to the total cost of the cycle, so that we know $c = \sum_{(i,j) \in C} c_{ij}$. Thus, we see that $c/l = \lambda$ is minimized, or in other words, we find a minimum mean cost cycle.
\end{sol}

\begin{prob}{2-d}
Let's assume the costs $c_{ij}$ are integers. Suggest a combinatorial algorithm (not based on linear programming) that uses binary search to find the right $\lambda$ to solve the dual problem. Can you use this to find a minimum mean cycle? Note: to know when you can terminate the search, you will need to lower bound the difference between the smallest and the next smallest mean cost of a cycle.
\end{prob}

\begin{sol}
First, we know that $\lambda \in [0, c_{max}]$ where $c_{max}$ is the maximum cost for any edge in the graph. This follows since we know that $(c_{ij} - \lambda) + y_i - y_j = 0$, so that we must have $c_{ij} \geq \lambda$. This means that we can perform a binary search for $\lambda$ inside of the interval $[0, c_{max}]$. 

We search by taking examining the interval $[a,b]$ and taking $(b-a)/2$. Once we have a candidate for $\lambda = (b-a)/2$, then we can check if this is feasible. Feasibility is checked by looking for a negative-cost cycle using the reduced edge costs with $\lambda = (b-a)/2$. We can augment the graph with this new $\lambda$, then check for negative-cost cycles by using Bellman-Ford. If we find a negative reduced cost cycle, then we must check for $\lambda$ which are smaller, so we recurse on the interval $[a, (b-a)/2]$. If there are no negative reduced cost cycles, then we can increase $\lambda$ while still being feasible, so we recurse on the interval $[(b-a)/2, b]$. 

We stop recursing when we have $b - a < \frac{1}{n^2}$, where $n$ is the total number of vertices in the graph. This follows because each cycle can consist of at most $n$ vertices each. We simply need to find a lower bound on the difference between the smallest and the second smallest mean cost of a cycle. However, we know that the mean costs $c_1 l_1 / k_1$ and $c_2 l_2 / k_2$ will have a difference $c_1 l_1 k_2 - c_2 l_2 k_1 >= 1$, since both of these values are integers. This implies that the mean costs differ by at least $\frac{1}{k_1 k_2} \geq \frac{1}{n^2}$. 

This means that we can be sure that we are done recursing when $b-a$ comes within $\frac{1}{n^2}$. This is because, by the integrality of costs, we are assured that $c_1 l_1 k_2 - c_2 l_2 k_1$ is an integer, and so we can bound the difference between the smallest and second smallest mean costs by $\frac{1}{n^2}$. Therefore, we can terminate the search when this occurs. 

We can then go and find the minimum mean cycle by using $\lambda$ in the reduced costs, then we can simply look for the minimum mean cost cycles by looking for zero edge weight cycles, which can be found by using a simple BFS.
\end{sol}

\newpage
\makenewtitle

\begin{prob}{3-a}
Argue that any LP optimization problem can be transformed into the form $min 0 \dot x$ subject to $Ax = b$, $x \geq 0$. This LP has optimum $0$ if it is feasible and $\infty$ if no. 
\end{prob}
\begin{sol}
We know that every LP optimization problem can be expressed in standard form. Therefore, we have the problem $\min cx$ such that $Ax = B, x\geq 0$. We derived in class that the dual of the standard form is $\max by$ such that $A^T y \geq c$. We $p$ be the solution of the primal and let $d$ be the solution of the dual. 

We know that in the optimal solution, we must have $p = d$, so we need to check whether $p = cx = by = d$, subject to all the conditions in both the primal and dual. Therefore, to check optimality, we look for feasibility of the following LP:
\begin{eqnarray}
by &=& cx \\
\text{ s.t. } Ax &=& b \\
x &\geq& 0 \\
Ay &\geq& c
\end{eqnarray}

Now, to find the optimum of either the primal or the dual, we just need to check feasibility of the above program. Finding a feasible solution will automatically give us an optimum solution by looking at the $p = by$ such that $by = cx$. Moreover, if either the primal or the dual is unbounded or infeasible, there will be no feasible solution to this LP. Notice that the feasibility of this program is equivalent to the minimization of $0 \dot x$, which is the objective function of the problem statement. If there are unbounded variables in the original primal, we can decompose $v = v^+ + v^-$ which represent the positive and negative portions of the unbounded variable. These can then enter into the variable set for the new LP.

Thus, we have created the problem $\min 0 \dot x$ subject to $Ax = b$ where $x \geq 0$, where we have transformed any standard form LP. 
\end{sol}

\begin{prob}{3-b}
What is the dual of this linear program?
\end{prob}
\begin{sol}
We can create a new variable $y$ which will correspond to the constraint $Ax = b$. We see that the new objective function will be given by $y$ amultiplied by its corresponding constraint, so we have $\max (Ax)^T y$. Since we know that $(Ax)^T = b^T$, we can rewrite this to $\max b^T y$. We are left to find the constraints of the dual.

We can use the coefficients from the primal's objective function to find the constant for the constraint. Moreover, we know that we want to set $A^T y$ as the left half of the constraint. Since we have $x \geq 0$, in the natural direction, we must have $A^T y$ in the other direction. We see that the constraint becomes $A^T y \leq 0$. Thus, the dual LP is:
\begin{eqnarray}
\max b^T y \\
\text{s.t.} \hspace{1cm} A^T y \leq 0
\end{eqnarray}
\end{sol}

\begin{prob}{3-c}
Argue if the primal is feasible then the dual has an obvious optimum solution.
\end{prob}
\begin{sol}
We know that all feasible solutions for the primal must have an objective of 0. Otherwise, we would have $0 \cdot x = \infty$, in which case the solution would not be feasible. Since we know that all feasible solutions to the primal have an objective of 0, we know by strong LP duality that all solutions of the dual must also have a solution of 0. We can also choose $y = 0$ and note that it satisfies $b^T y = 0$ and also the constraint $A^T y = 0$. Therefore, the obivous opimum solution for the dual is $y = 0$, leading to the objective function of value 0.
\end{sol}

\begin{prob}{3-d}
Deduce that, given the hypothetical algorithm above, you can build an LP algorithm that will solve any LP without knowing beforehand a dual solution, in the same asymptotic time bounds as the algorithm above.
\end{prob}
\begin{sol}
Let us use the magic algorithm given above to solve any LP without knowing a dual solution. First we know that any LP can be converted into standard form, then put in the form of problem 3-a, call this $LP'$. We know from problem 3-c that if the primal is feasible, then the dual has the optimum solution $y=0$. 

Thus, we can run the magic algorithm on $LP'$, using the dual solution $y=0$. We know that the algorithm finishes and gives an optimum solution in $O((m+n)^k)$ time if the dual solution is optimal. Since $y=0$ might not be an optimal solution if $LP'$ does not have any feasible solutions, then we must check to make sure the magic algorithm outputs a correct result. There exists some constant $c$ such that after $c(m+n)^k$ steps, we can cut off the algorithm and check whether it has returned an optimum value for $LP'$ yet.

If the value it outputs is feasible, so that $Ax = b$ and $x \geq 0$, then we know it must also be optimal for $LP'$ because the objective simply takes $\min 0 \cdot x$. However, if the output is infeasbile, then $LP'$ does not have any feasible solution. Notice that if $LP'$ has a feasible solution then we are guaranteed to find it using the magic algorithm in this way, and if $LP'$ does not have a feasible solution, then our check will discover this as well.

Now, we know that feasibility checking is equivalent to solving an LP. If we are given an LP in standard form, i.e. $\min cx$ such that $Ax = b$ and $x \geq 0$, then we just perform feasibility checking using the above algorithm to see if the problem $by = cx, Ax = b, x \geq 0, A^T y = c$ has any feasible solution. Our algorithm will return a feasible solution if it exists, and therefore, will also be able to provide an optimal solution to the original standard form LP. Thus, we ave been able to solve any LP in $O((m+n)^k)$ time using this magic algorithm.
\end{sol}

\newpage
\makenewtitle

\begin{prob}{4-a}
Given a standard form LP $min\{cx | Ax = b, x \geq 0 \}$, show how to define a different LP with an obvious feasible point, whose optima are precisely the feasible points of the original LP. 
\end{prob}
\begin{sol}
For each constraint in the constraint matrix defined by $Ax = b$, we will add a slack variable $y_i$ to create a new constraint matrix. Basically, for each equation $a_i x = b_i$ we will create an equation $a_i x + y_i = b_i$. We know that the equations originally are in the form $a_i x = b_i$ because we have a standard form LP. 

After we have defined these new variables $y_i$, we can create a vector $y = [y_1, y_2, \ldots, y_n]$. Now take the new LP:
\begin{eqnarray}
\min \sum_{i} y_i \\ 
\text{s.t} \hspace{1cm} Ax + y = b \\
y_i \geq 0 \forall i \\
x_i \geq 0 \forall i 
\end{eqnarray}

Now, we have new variables $y_i$ along with our previous variables $x_i$. However, we can trivially satisfy our constraints by setting $x_i = 0$ for all $i$, then setting $y_i = b_i$ for all $i$. This follows since $Ax = 0$, so we can be sure that $y=b$ will satisfy $Ax + y = b$. Moreover, we know that the optimum points of this LP are the $x_i$'s when $\sum_{i} y_i = 0$. Since all $y_i$ are positive, we must have $y = 0$ for this to occur.

However, if $y=0$, then we can see that our original constraint $Ax = b$ is satisfied. Since we constrained $x_i \geq 0 \forall i$, we will have found a feasible solution to our standard form LP with the optimum of our new LP.
\end{sol}

\begin{prob}{4-b}
Explain how this solves our problem, allowing us to use a simplex solver (which requires a feasible starting point) to solve arbitrary LPs without being given a feasible starting point.
\end{prob}
\begin{sol}
We can use our new LP $A$ from problem 4-a above to find a feasible starting point for simplex. First, we use the formulation above to create a problem whose optimum is an optimum for our original LP. Since we know that $x = 0$ and $y=b$ will suffice as a starting point in $A$, we can run simplex to find the optimum solution of $A$. 

If in the optimum we find $y_i = 0 \forall i$, then we know that $x$ will be a feasible starting point for our original LP. If this is not the case, then our original LP has no feasible points and thus is not feasible--this is because no variables $x_i$ can be used to satisfy the constraints $Ax = b$ and $x_i \geq 0 \forall i$. 

Now, once we have an feasible starting point for our original LP, we can run simplex to solve our LP.  
\end{sol}

\newpage
\makenewtitle

\begin{prob}{5-a}
Explain how a network design problem can be solved using the ellipsoid algorithm. In particular, give a linear program involving exponentially many constraints and provide an algorithm that, given any proposed network, finds a violated constraint in polynomial time. (Hint: the demands must be satisfied by flows, which are intimately related to cuts).
\end{prob}
\begin{sol}
We will create a linear program which is able to tell if a network has any violated constraints in polynomial time. First, we want to minimize the total cost of the network, so this will be our objective function. Next, we need to make sure for every vertex $s$ and $t$, we must have the flow between $s$ and $t$ be greater than $D_{s,t}$. 

In order to formulate this problem, we note that if we can find a flow from $s$ to $t$ which is greater than $D_{s,t}$ for each pair of vertices $s$ and $t$, then we have found a feasible solution. In order to find this flow, we can look at the cuts between $s$ and $t$. In essence, we must specify that all the cuts, and hence also the minimum cut, must have flow greater than $D_{s,t}$. Therefore, for every $s-t$ cut between vertices $s$ and $t$, we must have flow greater than $D_{s,t}$, which will guarantee that the min-cut has flow greater than $D_{s,t}$, which will in turn guarantee that a max-flow can be found with flow greater than $D_{s,t}$. 

Thus, we formulate the problem with constraints:
\begin{eqnarray}
f(c) &\geq& D_{s,t} \hspace{0.5cm} \forall c=(s,t) \text{ where } s,t \in V
\end{eqnarray}

Here we denote $c=(s,t)$ as an $s-t$ cut between vertices $s$ and $t$. Note that there are exponentially many of these cuts (each vertex can be either in or out of the $s$ subset. However, we note that we can find a violated constraint in polynomial time by using a max flow algorithm. Therefore, we have been able to provide an algorithm that, given any proposed network, finds a violated constraint in polynomial time. 
\end{sol}

\begin{prob}{5-b}
Argue that one can therefore find the minimum cost network design for the given input. 
\end{prob}
\begin{sol}

\end{sol}

\newpage
\makenewtitle

\begin{prob}{6-a}
Show that if Alice's mixed strategy is known, then Bob has a pure strategy serving as his best response.
\end{prob}
\begin{sol}
If Alice's mixed strategy is known, then there is some probability distribution over her strategies that is known to Bob. Let's say that Alice has some probability $x_i$ of choosing strategy $i$. We know that Bob's strategy is attempting to find $\max_{y_j = 1} \min_{x_i = 1} xAy$. The expected value for Bob of choosing strategy $j$ is given by $\sum_{i=1}^n x_i a_{ij}$. 

Since Bob attempts to solve the optimization problem $\max_{j} \sum_{i=1}^n x_i a_{ij}$, Bob's best response is the single strategy $j$ that maximizes this objective function. Therefore, Bob has a pure strategy of the choosing the objective maximizing response to Alice's mixed strategy.
\end{sol}

\begin{prob}{6-b}
Show how to convert each program above into a linear program, and thus find each an optimal strategy for both players in polynomial time.
\end{prob}
\begin{sol}
We know that Alice will choose the strategy that minimizes $xA$. Therefore, let us first look for Alice's strategy. We must find a lower bound $M$ of the columns of $Ay$. This can be done with a new linear program, making sure that the LP satisfies the properties of a mixed strategy. First, we must have $\sum_{i} y_i = 1$ because probabilities must sum to 1. Moreover, we must have non-negative probabilities so $y_i \geq 0$ for all $i$. Finally, in order to get a lower bound $M$ on the rows of $Ay$, we need to have $Ay \geq [M, M, M, \ldots, M]^T$. Finally, we want to maximize $M$ in order to get the tighest lower bound. Therefore our LP becomes:
\begin{eqnarray}
\max &M& \\ 
\text{s.t.} \hspace{1cm} Ay &\geq& [M, M, \ldots, M]^T \\
\sum_i y_i &=& 1 \\
y_i &\geq& 0 \forall i
\end{eqnarray}

Solving this LP means that we maximize the minimum of the rows of $Ay$, which is what Bob wanted to do in the first place. Once we have solved this LP, then we will have solved Bob's problem. To solve Alice's problem, we turn $M$ into the maximum of the columns of $xA$, then take $\min M$ as the objective function. The $x$ vector will give the probabilities for each strategy $i$ and will thus constitute the optimal mixed strategy. We chance our conditions to $xA \leq [M, M, \ldots, M]$, $\sum_{i} x_i = 1$, and $x_i \geq 0$ for all $i$.  
\end{sol}

\begin{prob}{6-c}
Give a plausible explanation for the meaning of your linear program in terms of the zero-sum matrix game (why does it give the optimum)?
\end{prob}
\begin{sol}
The linear program provided in problem 6-b looks for the maximum of the minimum of the mixed strategies. Basically, if Bob knew Alice's strategy, then Bob would always use strategy $j$ such that it maximized his objective function. We showed in problem 6-a that this is a pure strategy on Bob's part. 

However, since Alice employs a mixed strategy, Bob must guess which mixed strategy Alice employs. Therefore, Bob will probabilistically choose his strategy $j$ in response to what Alice will choose as her mixed strategy. The linear program defined in 6-b looks for Alice's optimal solution by finding the minimum $M$ that she would most likely choose. This analogy allows us to look at $M$ as the lower bound on the columns of $xA$.

Thus the LP solves Bob's problem by first looking at all the possibilities of what Alice will do, then finding the best possible strategies that Alice could take, and looking at Bob's response to these. Similar reasoning follows for solving Alice's problem.
\end{sol}

\begin{prob}{6-d}
Use strong duality to argue that the above two quantities are equal.
\end{prob}
\begin{sol}
We will start with the LP $min M$ subject to $xA \leq [M, M, \ldots, M]$, $\sum_{i} x_i = 1$, and $x_i \geq 0$ for all $i$. Taking the dual, we can create a new variable $z_i$ that corresponds to each strategy $i$. We also add another variable $E$. We go from a minimization problem to a maximization problem, using the constraints in the primal to create a new objective function. We will then haave $\max E$, where $E$ is our new variable. 

Using our previous objective function, we can create the constraints for our new dual. We have $\sum_{i} - z_i = 1$ and $z_i \leq 0$ for all $i$. These follow because we must flip the direction of the inequality, and because our new variables $z_i$ must be constrained according to the primal's objective. Finally, we see that we must have $Az \leq - [E, E, \ldots, E]^T$. If we set $-z_i = y_i$ with a simple change of variables, we have a the LP:
\begin{eqnarray}
\max &E& \\
\text{s.t.} \hspace{1cm} Ay &\geq& [E, E, \ldots, E]^T \\
\sum_{i} y_i &=& 1 \\
y_i &\geq& 0 \forall i
\end{eqnarray}

Notice that after taking the dual of our original LP, we have come up with Bob's problem. Therefore, we see that Alice and Bob's optimization problems are duals of each other. By strong duality, we know that Alice's optimum must be equal to Bob's optimum as long as the solutions are feasible. Thus the two quantities in problem 6-c are equal. 
\end{sol}

\end{document}
