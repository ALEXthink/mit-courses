\documentclass[psamsfonts]{amsart}

%-------Packages---------
\usepackage{amssymb,amsfonts}
\usepackage{enumerate}
\usepackage[margin=1in]{geometry}
\usepackage{amsthm}
\usepackage{theorem}
\usepackage{verbatim}
\usepackage{framed}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}

\newenvironment{sol}{\vspace{0.25cm}{\large \bfseries Solution:}}{\qedsymbol}
\newenvironment{prob}[1]{\begin{framed}{\large \bfseries Problem #1:}}{\end{framed}}
\newcommand{\makenewtitle}{
    \begin{center}
    {\huge \bfseries 6.854 Advanced Algorithms} \\
    Problem Set 11\\
    \vspace{0.25cm}
    {\bfseries John Wang} \\
    Collaborators:  
    \end{center}
    \vspace{0.5cm}
}


\bibliographystyle{plain}

\voffset = -10pt
\headheight = 0pt
\topmargin = -20pt
\textheight = 690pt

\begin{document}

\makenewtitle

\begin{prob}{1-a}
Suppose that only the nodes with even depth have an associated secondary structure. Show how the query algorithm can be adapted to answer queries correctly.
\end{prob}
\begin{sol}

\end{sol}

\newpage
\makenewtitle
\begin{prob}{2}
A problem last week found lines (and polygons) contained in a rectangle; here we consider finding lines crossing a rectangle. As a starting point, suppose you are given an interval tree data structure. This takes n possibly-overlapping intervals on the real line, and builds a size $n$ data structure that can, in $O(k + \log n)$ time, output the set of all intervals intersecting with a given query interval. Given such a data structure, show that you can build a size $O(n \log n)$ data structure that solves the following problem: given $n$ horizontal and vertical line segments in a plane and given a query rectangle, output all the segments that intersect the query rectangle in $O(k + \log^2 n)$ time. 
\end{prob}
\begin{sol}
Notice first that we can break apart our problem into two subproblems. Any query rectangle $R$ can be broken apart into two sets of edges. One set of edges takes the left and top edges, while the other set takes the right and bottom edges. The same solution can be applied to both of these sets, and the union of the two results will result in the final solution for a rectangle. Since there are 2 sets, there is only a constant number of extra queries that need to be performed, so that the solution can be reduced to solving the intersection problem for two adjacent edges of a rectangle.

We will further reduce the problem into a problem of a single edge. We can do this because if we have a top edge and a left edge, we can flip the $x$ and $y$ axes so that horizontal lines become vertical and vice versa. Thus, we apply this solution four times in order to get the number of intersections at the rectangle. This is still a constant multiple of the solution, which means we have reduced the problem to finding the intersections to a single line in the plane without increasing the asymptotic runtime.

Now let we have a query line $l$ which is horizontal, and we want to find the number of vertical and horizontal lines which intersect this line. We will create an interval tree data structure of size $n$ on the $x$ dimension. Thus, a query on the this interval tree will give all intervals in the $x$ direction which intersect the horizontal query line. The data structure we create will have subtrees rooted on each node. These subtrees will contain the $y$ coordinates of all the descendants of this particular node in the $x$ dimension's tree. The subtrees will be the interval tree data structure provided in the problem, while the top level tree will be a standard binary search tree. Just as we assembled the range tree for lines inside of a rectangle, we can assemble a tree for intersections of the rectangle. 

Since each $y$ coordinate term is only in the search trees which are above of it, and there are $O(\log n)$ nodes per $y$ tree, the total space is $O(n \log n)$. Next, querying for the intersections just involves a query for the $x$ coordinate part of the tree, then the $y$ coordinate intersections. This requires two queries on trees which can return queries in time $O(k + \log n)$, so the total query time is $O(\log^2 n + k)$ to output $k$ results. This is because it requires $O(\log n)$ time to search the standard binary search tree in the top level, and $O(\log n$ time to search the interval tree. 
\end{sol}

\newpage
\makenewtitle

\begin{prob}{3-a}
Argue that when the sweep line encounters a new point $p$, if $p$ is one point in the closest pair behind the sweep line, then the other point in the closest pair is inside the strip-and in fact, in a particular portion of the strip quite close to the new point.
\end{prob}
\begin{sol}
When looking for the new closest pair, we know that its distance $d'$ must be less than or equal to the current closest distance $d$. Therefore, we know that $d' \leq d$. This implies that the x-coordinate of the other point connected to $p$ must be $d' \leq d$ distance away from $p$. Since the strip is of distance $d$, we know that the other point will be in the strip, regardless of what angle it is connected to $p$ with. 

Moreover, we know that the point must be inside of a rectangle surrounding $p$. The rectangle extends $d$ in height upwards above $p$, and $d$ in height below $p$, and $d$ in width to the left. Thus subset of the strip si therefore a $2d \times d$ sized rectangle. We know that the other point must be inside of this triangle because it must be less than $d$ distance from $p$. This rectangle covers all points in the strip which are $d$ distance away, so therefore, it must cover the point as well.
\end{sol}

\begin{prob}{3-b}
Argue that in fact, this portion of the strip can only contain a constant number of points.
\end{prob}
\begin{sol}
Let us consider the rectangle $R$ and the point $p$ which is in the halfway-point on the right edge (of height $2d$) of the rectangle. We will look for candidate locations for other points $x$ and will try to pack as many points into the rectangle $R$ as possible. Notice first, however, that each point must be at least a distance $d$ away from any other point. This implies that there cannot exist any point inside a circle centered at some point of radius $d$. 

Using this representation, we can assign 6 points to the rectangle $R$ by placing one point on each vertex, and one point in the mid-way point of each of the long (length $2d$ edges). Notice that the circles that are mapped out by these 6 points are intersecting only at the boundary. However, moving any point in any configuration will cause non-boundary areas of the circles to intersect, which will cause an invalid allocation of points. Moreover, it is impossible to add any more points without having the circles intersect with the new point. Since the circles with 6 points have completely covered the entire rectangle, we see that there cannot be any more points added to the rectangle in any configuration. Thus, there are only a constant number of points that can be contained in the rectangle $R$.
\end{sol}

\begin{prob}{3-c}
Develop a data structure to associate with the sweep line so that these candidates for closest pair can be identified quickly ($O(log n)$ time per event), and show how to maintain this data structure as the line sweeps ($O(log n)$ time per event). Conclude an $O(n log n)$ time bound for closest pair.
\end{prob}
\begin{sol}
We will create a binary search tree which will at all times contain all of the points inside of the strip behind the sweep line. Notice that there are at most $n$ objects inside of the BST at any time because there are $n$ total objects. The BST will be keyed on the y-coordinates of horizontal points, and there will also be an array of the x-coordinates of all points which is sorted and stored (this requires time $O(n \log n)$. 

The sweep line will start at the beginning of the sorted array of x-coordinates. It will move to the right in discrete movements (at each time step moving to the x-coordinate of the next object in the sorted array). The new point will be inserted into the BST and we will check if there is a new minimum distance in all the points to the left of the sweep line. We will show that this operation can be done in $O(\log n)$ time. First, notice that the insertion into the BST requires $O(\log n)$ time since the tree is of maximum size $O(n)$. Next, we will use $d$, the previous minimum distance between any two points that are behind the sweep line and construct a rectangle as in problem 3-b. If the new point we have added to the BST has any neighbor which is closer than $d$, then we will necessarily find it in this rectangle, by our reasoning in the previous problem. 

Thus, we only need to check the distance between the new point we added to the BST and a constant number of points behind to sweep line to update $d$. In order to find the points in the rectangle, we perform a range query on the BST between $y - d$ and $y+d$, where $y$ is the y-coordinate of the new point we have added to the BST. This takes $O(\log n + 6) = O(\log n)$ time (by using the subtree size augmentation as shown in class). Thus, updating the distance $d$ requires $O(\log n)$ time. 

Finally, we need to worry about removing nodes which are no longer part of the strip of size $d$ (note that this is the updated size). We will go to our array of x-coordinates any binary search, looking for $sl - d$, where $sl$ is the x-coordinate of the sweep line. We will walk down the list and delete any point which is still in the BST and has $x$ coordinate which is less than $sl - d$. Once we reach the first node which is no longer part of the BST, we can stop scanning since we have already removed all points which are further back. This removal takes $O(\log n)$ for the initial binary search plus $O(l_i \log n)$ where $l_i$ is the number of nodes which are removed from the BST during event $i$. Therefore, the total cost of removal over the entire sequence is:
\begin{eqnarray}
\sum_{i=1}^n O(\log n) + O(l_i \log n) &=& O(n \log n) + O(\log n) \sum_{i=1}^n l_i \\
&=& O(n \log n)
\end{eqnarray}

This follows because there are a total of $n$ nodes which are removed from the BST since each node is inserted and removed only once. Therefore $\sum_{i=1}^n l_i = n$. Thus, we see that each removal requires an amortized $O(\log n)$ amount of time. Therefore, we see that each event requires $O(\log n)$ time for this data structure, and that calculating closest pair using this data structure requires $O(n \log n)$. 
\end{sol}

\begin{prob}{3-d}
Does the algorithm above generalize to any higher dimension $k$? What is the time bound as a function of $k$?
\end{prob}
\begin{sol}
The algorithm above can be generalized to a higher dimension by solving the problem recursively. Assume that we have solved the problem for some dimension $k-1$. In order to solve the problem for dimension $k$, we will need to break the problem up. We will use a sweep hyperplane which will be moved in all $k-1$ dimensions. Therefore, there will only be one dimension left for which we need to solve the problem, namely dimension $k$. Inside of the hyperplane which acts as our sweeping mechanism, we can find the closest pair of points in time $T(n, k-1)$. 

When we move the hyperplane to a new event, we will create a new rectangle $R$ of dimension $2d \times d$, following the same procedure we used in problem 3-d. Notice that if there is a set of points $p_1$ which has a distance to $p$ of less than $d$, then $p_1$ must rest in either the hyperplane or in the rectangle in dimension $k$. If it rests in the hyperplane, then we will find it by recursively applying our algorithm. If it rests in the rectangle, we can perform a range query on dimension $k$ and check the distance between a constant number of points. Performing the range query requires $O(\log n)$ time if we have created a BST on dimension $k$ (using the same mechanism as before to insert and delete points). The total time for this is therefore $T(n, k) = O(\log n) + T(n, k-1)$. Since we know that $T(n, 2) = O(n \log n)$, we see that solving this recursion results in $T(n, k) = O(n \log^{k-1} n)$.  
\end{sol}

\begin{prob}{3-e}
Alternatively, suppose you construct the Voronoi diagram on the points. Show how the closest pair can then be identified in $O(n)$ time. This gives an alternative $O(n \log n)$ time algorithm in 2 dimensions.
\end{prob}
\begin{sol}
Notice that we can build a Voronoi diagram in $O(n \log n$ time using the construction method described in class. Next, notice that the closest pair of points must be in cells which are adjacent to each other in the Voronoi diagram. This follows because there must be a single line segment separating them since they are the closest points together so no other bisecting line can come in between. 

Suppose by contradiction that there was some other line in the Voronoi diagram which separted the two closest points $x$ and $y$. This means that the line $l$ bisecting $x$ and $y$ does not show up in the Voronoi diagram, which implies that there must be some other point or sets of points which are closer together, and thus the bisecting line between these closer points takes precedence over $l$. This contradicts the fact that $x$ and $y$ are the two closest points.

This means that as long one searches all of the adjacent cells of some cell $x$, for all $x$, then one can find the pair of closest points by calculating the distance of each adjacent cell and taking the minimum after all distances have been calculated. Moreover, notice that for each two adjacent cells, there must exist an edge in the Voronoi diagram which separates the two cells. Thus, the number of adjacent cells that need to be examined is bounded by the number of edges in the Voronoi diagram. We showed in class that the number of edges is $O(n)$, which means only $O(n)$ distance calculations need to be made.

Therefore, we can find the closest pair of points in $O(n) + O(n \log n) = O(n)$ time using a Voronoi diagram.
\end{sol}

\newpage
\makenewtitle

\begin{prob}{4}
\end{prob}
\begin{sol}
\end{sol}

\end{document}
